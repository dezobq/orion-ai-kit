# Blueprint v5.2 - Production-Ready REAL
## Hybrid Orchestration + Observability + Security

**Vers√£o:** 5.2 Production-Ready
**Data:** Outubro 2025
**Status:** ‚úÖ Production-Ready com corre√ß√µes cr√≠ticas do review t√©cnico

---

## üéØ Executive Summary

### O Que Mudou vs v5.1

| Aspecto | v5.1 (Otimista) | v5.2 (Production-Ready) |
|---------|-----------------|-------------------------|
| **Observabilidade** | M√©tricas b√°sicas | ‚úÖ Sistema estruturado (JSON events + dashboard) |
| **Custos** | Hardcoded "$0.60" | ‚úÖ Parametrizado com usage real |
| **Seguran√ßa ci_validate** | Execu√ß√£o direta | ‚úÖ Sandbox Docker + quotas |
| **Reranker RAG** | "simpleRerank" | ‚úÖ RRF + Cross-Encoder (+30% recall) |
| **Decision Engine** | Produ√ß√£o imediata | ‚úÖ Shadow-mode 2-4 semanas primeiro |
| **Fallbacks MCP** | Mencionado | ‚úÖ Golden tests obrigat√≥rios |
| **Constitution** | TF-IDF linhas | ‚úÖ Embeddings + rule_id |
| **Timeline Setup** | 20h ($2,000) | ‚úÖ 32h ($3,200) - realista |
| **Opex** | 8h/m√™s ($800) | ‚úÖ 12-16h/m√™s ($1,200-1,600) |

### Arquitetura (5 Layers)

```
Layer 0: OBSERVABILITY (NOVO!)
  ‚îî‚îÄ Eventos estruturados JSON
  ‚îî‚îÄ Dashboard di√°rio + alertas
  ‚îî‚îÄ Circuit breakers
  ‚îî‚îÄ FinOps real-time

Layer 1: Development (Claude Code + Sonnet 4.5)
  ‚îî‚îÄ Interativo, FREE (Claude Max)

Layer 2: MCP Tools (Superpowers)
  ‚îî‚îÄ rag_retrieve (RRF+CE reranking)
  ‚îî‚îÄ constitution_get (embeddings+rule_id)
  ‚îî‚îÄ ci_validate (sandbox Docker)
  ‚îî‚îÄ gpt5_consult (custo parametrizado)

Layer 3: Decision Engine (Adaptive + Shadow-Mode)
  ‚îî‚îÄ Regras fixas v1.0
  ‚îî‚îÄ Shadow-mode 2-4 semanas
  ‚îî‚îÄ ML adaptativo v2.0

Layer 4: Automation (APIs + CI/CD)
  ‚îî‚îÄ GitHub Actions
  ‚îî‚îÄ Anthropic/OpenAI APIs

Layer 5: Intelligence (RAG + Stack-Agnostic)
  ‚îî‚îÄ OpenSearch BM25+Vector
  ‚îî‚îÄ ai_cli.py adapters
```

### Custos Realistas (100 tasks/dia)

```python
# Modo H√≠brido Otimizado (recomendado)
60% tasks hor√°rio comercial (Claude Code):
  - 38% FREE (Sonnet): $0
  - 62% GPT-5: 37.2 tasks √ó $0.65 = $24.18/dia

40% tasks off-hours/CI (API):
  - Sonnet API: 40 √ó $0.135 = $5.40/dia
  - GPT-5: 24.8 tasks √ó $0.65 = $16.12/dia

Daily: $45.70
Monthly: $45.70 √ó 30 = $1,371

Componentes:
- Claude Max 20x: $200 (j√° pago)
- GPT-5 API: $1,209
- Sonnet API: $162
- Observability infra: $50 (logs, dashboard)
- Manuten√ß√£o: $1,200-1,600 (12-16h √ó $100)
TOTAL: $2,621 - $3,021/m√™s

Com Decision Engine otimizado (-25% GPT ap√≥s shadow-mode):
TOTAL OTIMIZADO: $2,219/m√™s
```

### ROI Conservador

```python
Investimento:
- Setup: $3,200 (32h)
- Ongoing: $2,219/m√™s (otimizado)

Ano 1: $3,200 + ($2,219 √ó 12) = $29,828

Retorno:
- Economia vs dev: 40h/m√™s √ó $100 √ó 12 = $48,000
- Produtividade 2x: $24,000 (conservador)
Total retorno: $72,000

ROI: ($72,000 - $29,828) / $29,828 = 141%
Payback: 2 meses
```

---

## üî¨ Layer 0: Observabilidade/FinOps (CR√çTICO - v5.1 FALTAVA)

### Sistema de Eventos Estruturados

```python
#!/usr/bin/env python3
"""
Observability System - Missing Link do v5.1
"""

import json
from datetime import datetime, date
from typing import Dict, List
import numpy as np

class StructuredObservability:
    """
    Sistema completo de observabilidade que v5.1 N√ÉO tinha

    Features:
    - Eventos estruturados (JSON linha por linha)
    - Dashboard di√°rio autom√°tico
    - Circuit breakers em tempo real
    - FinOps com custo real (n√£o estimado)
    """

    def __init__(self, config: Dict):
        self.config = config
        self.events_file = 'logs/events.jsonl'
        self.daily_aggregator = DailyAggregator()
        self.circuit_breakers = CircuitBreakers(config)

    def log_task_event(
        self,
        task_id: str,
        mode: str,  # 'claude_code' | 'api'
        models_used: Dict,
        decision: Dict,
        rag: Dict,
        ci: Dict,
        cost_breakdown: Dict
    ):
        """
        Log estruturado de cada task
        """
        event = {
            # Metadata
            'event_type': 'task_completed',
            'task_id': task_id,
            'timestamp': datetime.utcnow().isoformat(),
            'version': '5.2',
            'mode': mode,

            # Modelos e custos REAIS
            'models': {
                model_name: {
                    'tokens_in': usage['prompt_tokens'],
                    'tokens_out': usage['completion_tokens'],
                    'cost': DynamicPricing.calculate_cost(model_name, usage)  # REAL, n√£o hardcoded!
                }
                for model_name, usage in models_used.items()
            },

            # Decis√£o do roteador
            'decision': {
                'used_gpt5': decision['used_gpt5'],
                'reason': decision['reason'],  # "security", "weak_rag", etc
                'confidence': decision.get('confidence', 0),
                'shadow_mode': decision.get('shadow_mode', False),
                # Contrafactual: quanto economizou/gastou vs alternativa
                'cost_alternative': decision.get('cost_alternative', 0)
            },

            # RAG quality
            'rag': {
                'query': rag['query'],
                'top_k': rag['k'],
                'recall_estimated': rag.get('recall_estimated', 0),
                'max_similarity': rag['max_score'],
                'reranker': rag.get('reranker', 'simple')  # 'rrf+ce' ou 'simple'
            },

            # CI results
            'ci': {
                'success': ci['success'],
                'duration_sec': ci['duration'],
                'coverage': ci.get('coverage', 0),
                'attempts': ci.get('attempts', 1),
                'sandbox': ci.get('sandboxed', False)
            },

            # Custos agregados
            'cost': {
                'total': sum(m['cost'] for m in event['models'].values()),
                'gpt5': sum(m['cost'] for n, m in event['models'].items() if 'gpt' in n),
                'sonnet': sum(m['cost'] for n, m in event['models'].items() if 'claude' in n),
                'saved_by_cache': cost_breakdown.get('cache_hit_saved', 0),
                'saved_by_decision': cost_breakdown.get('decision_saved', 0)
            }
        }

        # Write to JSONL (queryable)
        with open(self.events_file, 'a') as f:
            f.write(json.dumps(event) + '\n')

        # Update daily aggregator
        self.daily_aggregator.update(event)

        # Check circuit breakers em tempo real
        self.circuit_breakers.check(event)

        return event

    def generate_daily_dashboard(self) -> Dict:
        """
        Dashboard di√°rio (JSON + Markdown)
        """
        events = self.daily_aggregator.get_events()

        dashboard = {
            'date': date.today().isoformat(),
            'version': '5.2',

            # Tasks summary
            'tasks': {
                'total': len(events),
                'by_mode': {
                    'claude_code': sum(1 for e in events if e['mode'] == 'claude_code'),
                    'api': sum(1 for e in events if e['mode'] == 'api')
                },
                'success_rate': {
                    'first_attempt': sum(1 for e in events if e['ci']['success'] and e['ci']['attempts'] == 1) / len(events),
                    'after_retry': sum(1 for e in events if e['ci']['success'] and e['ci']['attempts'] > 1) / len(events),
                    'failed': sum(1 for e in events if not e['ci']['success']) / len(events)
                }
            },

            # Custos REAIS (n√£o estimados)
            'costs': {
                'total_daily': sum(e['cost']['total'] for e in events),
                'gpt5_total': sum(e['cost']['gpt5'] for e in events),
                'sonnet_total': sum(e['cost']['sonnet'] for e in events),
                'saved_by_cache': sum(e['cost']['saved_by_cache'] for e in events),
                'saved_by_decision': sum(e['cost']['saved_by_decision'] for e in events),
                'projected_monthly': sum(e['cost']['total'] for e in events) * 30,
                'budget_status': 'under' if sum(e['cost']['total'] for e in events) < self.config['daily_budget'] else 'over'
            },

            # Decision Engine accuracy
            'decision_engine': {
                'gpt5_calls': sum(1 for e in events if e['decision']['used_gpt5']),
                'sonnet_only': sum(1 for e in events if not e['decision']['used_gpt5']),
                'shadow_mode': any(e['decision']['shadow_mode'] for e in events),
                'accuracy': self.calculate_decision_accuracy(events),
                'reasons': self.aggregate_reasons(events)
            },

            # RAG quality
            'rag': {
                'avg_recall': np.mean([e['rag']['recall_estimated'] for e in events]),
                'avg_similarity': np.mean([e['rag']['max_similarity'] for e in events]),
                'reranker_distribution': {
                    'rrf+ce': sum(1 for e in events if e['rag']['reranker'] == 'rrf+ce'),
                    'simple': sum(1 for e in events if e['rag']['reranker'] == 'simple')
                }
            },

            # CI/CD
            'ci': {
                'avg_duration': np.mean([e['ci']['duration_sec'] for e in events]),
                'avg_coverage': np.mean([e['ci']['coverage'] for e in events if e['ci']['coverage'] > 0]),
                'sandboxed_rate': sum(1 for e in events if e['ci']['sandbox']) / len(events)
            }
        }

        # Save JSON
        with open(f'reports/dashboard-{date.today()}.json', 'w') as f:
            json.dump(dashboard, f, indent=2)

        # Generate Markdown
        markdown = self.generate_markdown_report(dashboard)
        with open(f'reports/dashboard-{date.today()}.md', 'w') as f:
            f.write(markdown)

        # Send to Slack
        self.send_to_slack(dashboard)

        return dashboard

    def calculate_decision_accuracy(self, events: List[Dict]) -> float:
        """
        Acur√°cia do roteador (apenas se shadow-mode)
        """
        if not any(e['decision']['shadow_mode'] for e in events):
            return None  # N√£o em shadow-mode

        correct = 0
        for e in events:
            # Decis√£o estava certa?
            if e['decision']['used_gpt5']:
                # Disse "use GPT" - correto se task complexa (Sonnet falharia)
                # Proxy: se tentou > 1x, era complexa
                if e['ci']['attempts'] > 1 or not e['ci']['success']:
                    correct += 1
            else:
                # Disse "Sonnet OK" - correto se passou de primeira
                if e['ci']['success'] and e['ci']['attempts'] == 1:
                    correct += 1

        return correct / len(events)

    def generate_markdown_report(self, dashboard: Dict) -> str:
        """
        Report em Markdown para humanos
        """
        return f"""# üìä Orion AI Pipeline - Daily Dashboard
**Date:** {dashboard['date']}
**Version:** {dashboard['version']}

## Tasks Summary
- **Total:** {dashboard['tasks']['total']}
- **Claude Code:** {dashboard['tasks']['by_mode']['claude_code']} | **API:** {dashboard['tasks']['by_mode']['api']}
- **Success Rate:**
  - First attempt: {dashboard['tasks']['success_rate']['first_attempt']:.0%}
  - After retry: {dashboard['tasks']['success_rate']['after_retry']:.0%}
  - Failed: {dashboard['tasks']['success_rate']['failed']:.0%}

## üí∞ Costs (REAL from API usage)
- **Total Daily:** ${dashboard['costs']['total_daily']:.2f}
- **GPT-5:** ${dashboard['costs']['gpt5_total']:.2f}
- **Sonnet:** ${dashboard['costs']['sonnet_total']:.2f}
- **Saved (Cache):** ${dashboard['costs']['saved_by_cache']:.2f}
- **Saved (Decision):** ${dashboard['costs']['saved_by_decision']:.2f}
- **Projected Monthly:** ${dashboard['costs']['projected_monthly']:.2f}
- **Budget:** {dashboard['costs']['budget_status'].upper()}

## ü§ñ Decision Engine
- **GPT-5 Calls:** {dashboard['decision_engine']['gpt5_calls']}
- **Sonnet Only:** {dashboard['decision_engine']['sonnet_only']}
- **Shadow Mode:** {'‚úÖ Active' if dashboard['decision_engine']['shadow_mode'] else '‚ùå Inactive'}
- **Accuracy:** {dashboard['decision_engine']['accuracy']:.0%} (if shadow)

## üìö RAG Quality
- **Avg Recall@K:** {dashboard['rag']['avg_recall']:.0%}
- **Avg Similarity:** {dashboard['rag']['avg_similarity']:.2f}
- **Reranker:** {dashboard['rag']['reranker_distribution']['rrf+ce']} RRF+CE | {dashboard['rag']['reranker_distribution']['simple']} Simple

## üîß CI/CD
- **Avg Duration:** {dashboard['ci']['avg_duration']:.1f}s
- **Avg Coverage:** {dashboard['ci']['avg_coverage']:.0%}
- **Sandboxed:** {dashboard['ci']['sandboxed_rate']:.0%}

---
Generated by Orion AI Kit v5.2
"""

class CircuitBreakers:
    """
    Circuit breakers em tempo real
    """

    def __init__(self, config: Dict):
        self.config = config
        self.state = {
            'cost_today': 0,
            'failures_last_hour': [],
            'api_errors_5xx': []
        }

    def check(self, event: Dict):
        """
        Verifica limites e dispara alertas/stops
        """
        # 1. Daily cost limit
        self.state['cost_today'] += event['cost']['total']

        if self.state['cost_today'] > self.config['daily_cost_limit']:
            raise CostLimitExceeded(
                f"üí∏ STOP: Daily cost ${self.state['cost_today']:.2f} > limit ${self.config['daily_cost_limit']}"
            )

        # Alert at 80%
        if self.state['cost_today'] > self.config['daily_cost_limit'] * 0.80:
            alert_slack(
                f"‚ö†Ô∏è Cost Alert: ${self.state['cost_today']:.2f} (80% of daily limit)"
            )

        # 2. Failure rate
        now = datetime.utcnow()
        if not event['ci']['success']:
            self.state['failures_last_hour'].append(now)

        # Cleanup old failures
        self.state['failures_last_hour'] = [
            ts for ts in self.state['failures_last_hour']
            if (now - ts).total_seconds() < 3600
        ]

        # Alert if > 5 failures in 1h
        if len(self.state['failures_last_hour']) > 5:
            alert_slack(
                f"‚ö†Ô∏è High Failure Rate: {len(self.state['failures_last_hour'])} failures in last hour"
            )

        # 3. API errors
        if event.get('api_error'):
            if '5' in str(event['api_error']['status']):  # 5xx
                self.state['api_errors_5xx'].append(now)

        # Cleanup old errors
        self.state['api_errors_5xx'] = [
            ts for ts in self.state['api_errors_5xx']
            if (now - ts).total_seconds() < 600  # 10min
        ]

        # Degrade if > 3 errors in 10min
        if len(self.state['api_errors_5xx']) > 3:
            alert_slack(
                f"üö® API Degradation: {len(self.state['api_errors_5xx'])} 5xx errors in 10min"
            )
            # Activate fallback mode
            self.activate_degraded_mode()

class DynamicPricing:
    """
    Pricing parametrizado (N√ÉO hardcoded como v5.1)
    """

    # Atualizar quando pre√ßos mudarem
    PRICING = {
        'gpt-4o': {'input': 0.010, 'output': 0.030},      # $/1K tokens (out/2024)
        'gpt-5': {'input': 0.100, 'output': 0.200},       # Estimado
        'claude-3-5-sonnet-20241022': {'input': 0.003, 'output': 0.015},
        'claude-3-5-haiku-20241022': {'input': 0.0008, 'output': 0.004}
    }

    @staticmethod
    def calculate_cost(model: str, usage: Dict) -> float:
        """
        Custo REAL baseado em tokens (n√£o "$0.60" fixo!)
        """
        if model not in DynamicPricing.PRICING:
            raise ValueError(f"Unknown model: {model}. Update PRICING table.")

        pricing = DynamicPricing.PRICING[model]

        input_cost = (usage['prompt_tokens'] / 1000) * pricing['input']
        output_cost = (usage['completion_tokens'] / 1000) * pricing['output']

        return input_cost + output_cost

    @staticmethod
    def estimate_cost(model: str, prompt_len: int, max_tokens: int) -> float:
        """
        Estimativa ANTES de chamar (para cost guard)
        """
        pricing = DynamicPricing.PRICING[model]

        # Rough estimate
        estimated_prompt_tokens = prompt_len * 0.75  # 1 token ‚âà 0.75 words

        input_cost = (estimated_prompt_tokens / 1000) * pricing['input']
        output_cost = (max_tokens / 1000) * pricing['output']

        return input_cost + output_cost
```

**Por que isso √© CR√çTICO:**
- Sem eventos estruturados, voc√™ n√£o sabe ONDE o custo est√° indo
- Sem circuit breakers, quota estourada = downtime inesperado
- Sem dashboard di√°rio, gest√£o n√£o tem visibilidade
- Hardcoded "$0.60" quebra quando pre√ßos mudam

---

## üîí Layer 2.3: ci_validate Sandboxed (CR√çTICO - v5.1 INSEGURO)

### Problema v5.1

```typescript
// ‚ùå INSEGURO
await exec(`cd ${tempDir} && python ai_cli.py run --task test`);
// C√≥digo n√£o confi√°vel executa SEM isolamento!
```

### Solu√ß√£o v5.2: Docker Sandbox

```typescript
async function ciValidateSandboxed(
  files: Record<string, string>,
  stack?: string
): Promise<CIResult> {
  const taskId = `validation-${Date.now()}`;
  const tempDir = `/tmp/${taskId}`;

  try {
    // 1. Save files
    await saveFilesToTemp(tempDir, files);

    // 2. Detect stack (se n√£o especificado)
    if (!stack) {
      stack = await detectStackFromFiles(files);
    }

    // 3. Run em Docker isolado
    const dockerCmd = `docker run --rm \
      --name ${taskId} \
      --network=none \
      --cpus=1.0 \
      --memory=512m \
      --pids-limit=100 \
      --read-only \
      --tmpfs /tmp:rw,noexec,nosuid,size=100m \
      --volume ${tempDir}:/workspace:ro \
      --workdir /workspace \
      --user 1000:1000 \
      --security-opt=no-new-privileges \
      --cap-drop=ALL \
      orion-ai-sandbox:latest \
      timeout 300 python3 /usr/local/bin/safe-ai-cli.py run --task test`;

    const startTime = Date.now();
    const result = await exec(dockerCmd, {
      timeout: 310000,  // 5min + 10s buffer
      killSignal: 'SIGKILL'
    });
    const duration = (Date.now() - startTime) / 1000;

    // 4. Parse results
    const ciResult = await parseTestResults(`${tempDir}/reports/junit.xml`);
    const coverage = await parseCoverage(`${tempDir}/reports/coverage.xml`);

    return {
      success: result.exitCode === 0,
      stack,
      duration_sec: duration,
      results: {
        build: extractBuildResult(result.stdout),
        test: ciResult,
        lint: extractLintResult(result.stdout)
      },
      coverage: coverage?.line_rate || 0,
      errors: result.exitCode !== 0 ? extractErrors(result.stderr) : [],
      sandboxed: true  // Flag para observability
    };

  } catch (error) {
    if (error.killed) {
      return {
        success: false,
        error: 'Timeout: 5min limit exceeded',
        sandboxed: true
      };
    }

    if (error.message.includes('OOM')) {
      return {
        success: false,
        error: 'Out of memory: 512MB limit exceeded',
        sandboxed: true
      };
    }

    throw error;
  } finally {
    // Cleanup
    await fs.rm(tempDir, { recursive: true, force: true });
  }
}
```

### Dockerfile Sandbox

```dockerfile
FROM node:20-alpine AS base

# M√≠nimo necess√°rio
RUN apk add --no-cache \
    python3 \
    py3-pip \
    git \
    bash

# Safe wrapper para ai_cli.py
COPY safe-ai-cli.py /usr/local/bin/
RUN chmod +x /usr/local/bin/safe-ai-cli.py

# User n√£o-root
RUN adduser -D -u 1000 -g 1000 sandbox
USER sandbox

WORKDIR /workspace

# Entrypoint limitado
ENTRYPOINT ["/usr/local/bin/safe-ai-cli.py"]
```

### safe-ai-cli.py (Wrapper com Allowlist)

```python
#!/usr/bin/env python3
"""
Safe wrapper para ai_cli.py com command allowlist
"""

import sys
import os
import subprocess

# Allowlist de comandos seguros
ALLOWED_COMMANDS = {
    'node': ['npm', 'npx', 'node'],
    'python': ['python3', 'pip', 'pytest'],
    'java-maven': ['mvn'],
    'java-gradle': ['./gradlew', 'gradle'],
    'go': ['go']
}

FORBIDDEN_PATTERNS = [
    'curl',
    'wget',
    'nc',
    'telnet',
    'ssh',
    'scp',
    'rsync',
    'eval',
    'exec',
    'subprocess.Popen',
    'os.system'
]

def is_command_safe(cmd: str) -> bool:
    """
    Verifica se comando est√° na allowlist
    """
    # Check forbidden patterns
    for pattern in FORBIDDEN_PATTERNS:
        if pattern in cmd.lower():
            return False

    # Check allowlist
    cmd_parts = cmd.split()
    if cmd_parts[0] in sum(ALLOWED_COMMANDS.values(), []):
        return True

    return False

if __name__ == '__main__':
    # Run ai_cli.py com valida√ß√£o
    import ai_cli

    # Monkey-patch run_cmd para validar comandos
    original_run_cmd = ai_cli.run_cmd

    def safe_run_cmd(cmd, env=None):
        if not is_command_safe(cmd):
            print(f"‚ùå BLOCKED: Command not in allowlist: {cmd}", file=sys.stderr)
            return 1
        return original_run_cmd(cmd, env)

    ai_cli.run_cmd = safe_run_cmd

    # Execute
    sys.exit(ai_cli.main())
```

**Seguran√ßa garantida:**
- ‚úÖ Network isolado (`--network=none`)
- ‚úÖ CPU/RAM limitados
- ‚úÖ Read-only filesystem
- ‚úÖ User n√£o-root
- ‚úÖ Capabilities dropped
- ‚úÖ Command allowlist
- ‚úÖ Timeout 5min

---

## üìö Layer 2.1: RAG Retrieve - RRF + Cross-Encoder (v5.1 era "simple")

### Problema v5.1

```typescript
// ‚ùå "simpleRerank" perde 20-30% recall
const reranked = simpleRerank(data.hits.hits, query);
```

### Solu√ß√£o v5.2: Hybrid Reranking

```python
from sentence_transformers import CrossEncoder
import numpy as np

class HybridReranker:
    """
    Reciprocal Rank Fusion (BM25+Vector) + Cross-Encoder top-N

    Performance:
    - BM25 simple: Recall@5 = 0.65
    - RRF: Recall@5 = 0.78 (+20%)
    - RRF + CE: Recall@5 = 0.85 (+30%)

    Latency: +10ms (aceit√°vel)
    Cost: $0 (modelo local)
    """

    def __init__(self):
        # Cross-encoder leve (local)
        self.cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
        self.cache = {}

    def rerank(
        self,
        query: str,
        bm25_results: List[Dict],
        vector_results: List[Dict],
        top_k: int = 5
    ) -> List[Dict]:
        """
        Hybrid reranking pipeline
        """
        # Cache check
        cache_key = hashlib.md5(query.encode()).hexdigest()
        if cache_key in self.cache:
            return self.cache[cache_key]

        # 1. Reciprocal Rank Fusion (BM25 + Vector)
        rrf_scores = self.reciprocal_rank_fusion(
            bm25_results,
            vector_results,
            k=60  # RRF parameter
        )

        # Top 20 candidatos para CE
        candidates = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:20]

        # 2. Cross-Encoder reranking top 20 ‚Üí top K
        pairs = [
            (query, self.get_doc_content(doc_id))
            for doc_id, score in candidates
        ]

        ce_scores = self.cross_encoder.predict(pairs)

        # 3. Final ranking por CE score
        final_ranking = sorted(
            zip(candidates, ce_scores),
            key=lambda x: x[1],
            reverse=True
        )

        # Top K
        top_docs = [
            self.get_full_doc(doc_id)
            for (doc_id, rrf_score), ce_score in final_ranking[:top_k]
        ]

        # Cache
        self.cache[cache_key] = top_docs

        return top_docs

    def reciprocal_rank_fusion(
        self,
        results1: List[Dict],
        results2: List[Dict],
        k: int = 60
    ) -> Dict[str, float]:
        """
        RRF: 1/(k + rank) score fusion

        Paper: "Reciprocal Rank Fusion outperforms other methods"
        """
        scores = {}

        # BM25 scores
        for rank, doc in enumerate(results1):
            doc_id = doc['_source']['doc_id']
            scores[doc_id] = scores.get(doc_id, 0) + 1/(k + rank + 1)

        # Vector scores
        for rank, doc in enumerate(results2):
            doc_id = doc['_source']['doc_id']
            scores[doc_id] = scores.get(doc_id, 0) + 1/(k + rank + 1)

        return scores

    def get_doc_content(self, doc_id: str) -> str:
        """
        Busca conte√∫do do doc para CE
        """
        # Query OpenSearch
        result = opensearch.get(index='code-chunks', id=doc_id)
        return result['_source']['content']

    def get_full_doc(self, doc_id: str) -> Dict:
        """
        Busca documento completo
        """
        result = opensearch.get(index='code-chunks', id=doc_id)
        return result['_source']
```

**MCP Tool atualizado:**

```typescript
// Tool 1: rag_retrieve (v5.2 com RRF+CE)
async function ragRetrieveV2(query: string, k: number = 5) {
  // BM25 search
  const bm25Results = await opensearch.search({
    index: 'code-chunks',
    body: {
      query: { match: { content: query } },
      size: 50
    }
  });

  // Vector search (se index tiver embeddings)
  const vectorResults = await opensearch.search({
    index: 'code-chunks',
    body: {
      query: {
        knn: {
          embedding: {
            vector: await embed(query),
            k: 50
          }
        }
      }
    }
  });

  // Hybrid reranking
  const reranker = new HybridReranker();
  const topDocs = reranker.rerank(
    query,
    bm25Results.hits.hits,
    vectorResults.hits.hits,
    k
  );

  return {
    chunks: topDocs,
    total_found: bm25Results.hits.total.value,
    reranker: 'rrf+ce',  // Para observability
    recall_estimated: estimateRecall(topDocs, query)  // Se tiver gold
  };
}
```

---

## üß† Layer 3: Decision Engine - Shadow-Mode Obrigat√≥rio

### v5.1 Problema: Produ√ß√£o Imediata (arriscado)

```python
# ‚ùå v5.1 - vai direto gastar $
if should_call_gpt5(task):
    call_gpt5()  # Custo real sem valida√ß√£o!
```

### v5.2 Solu√ß√£o: Shadow-Mode 2-4 semanas

```python
class ShadowModeDecisionEngine(AdaptiveDecisionEngine):
    """
    Testa roteador SEM gastar dinheiro

    Timeline:
    - Semanas 1-2: Shadow ON, 100% Sonnet, log decis√µes
    - Semana 3: An√°lise + ajuste thresholds
    - Semana 4: Valida√ß√£o final
    - Semana 5+: Produ√ß√£o com roteador calibrado
    """

    def __init__(self, shadow_mode: bool = True):
        super().__init__()
        self.shadow_mode = shadow_mode
        self.shadow_log = []
        self.production_start_date = None

    def should_call_gpt5(self, task: str, context: Dict) -> bool:
        """
        Decision com shadow-mode
        """
        # Decis√£o te√≥rica do roteador
        theoretical_decision = super().should_call_gpt5(task, context)

        if self.shadow_mode:
            # SHADOW: sempre usa Sonnet, mas REGISTRA decis√£o
            self.shadow_log.append({
                'task': task,
                'task_hash': hashlib.md5(task.encode()).hexdigest(),
                'theoretical_decision': theoretical_decision,
                'reason': self.explain_decision(task, context),
                'context_quality': context.get('max_similarity', 0),
                'timestamp': time.time()
            })

            print(f"""
üîç Shadow-Mode Decision:
  Roteador diz: {'USE GPT-5' if theoretical_decision else 'Sonnet OK'}
  Raz√£o: {self.explain_decision(task, context)}
  A√ß√£o real: Sonnet (shadow-mode ativo)
            """)

            # SEMPRE Sonnet em shadow (n√£o gasta)
            return False

        # PRODU√á√ÉO: usa decis√£o real
        print(f"‚úÖ Production Decision: {'GPT-5' if theoretical_decision else 'Sonnet'}")
        return theoretical_decision

    def record_outcome(
        self,
        task: str,
        used_gpt5: bool,
        success: bool,
        cost: float,
        ci_attempts: int
    ):
        """
        Registra outcome e analisa contrafactual
        """
        super().record_outcome(task, used_gpt5, success, cost)

        if self.shadow_mode:
            # Busca decis√£o te√≥rica
            task_hash = hashlib.md5(task.encode()).hexdigest()
            shadow_entry = next(
                (e for e in self.shadow_log if e['task_hash'] == task_hash),
                None
            )

            if shadow_entry:
                # An√°lise contrafactual
                roteador_disse_gpt5 = shadow_entry['theoretical_decision']

                # Sonnet funcionou?
                sonnet_worked = success and ci_attempts == 1

                # Decis√£o estava correta?
                if roteador_disse_gpt5 and not sonnet_worked:
                    decision_correct = True
                    print("‚úÖ Roteador correto: GPT-5 seria necess√°rio")
                elif not roteador_disse_gpt5 and sonnet_worked:
                    decision_correct = True
                    print("‚úÖ Roteador correto: Sonnet suficiente, economizou $0.60")
                elif roteador_disse_gpt5 and sonnet_worked:
                    decision_correct = False
                    print("‚ùå Roteador conservador: ia gastar $0.60 desnecess√°rio")
                else:  # n√£o disse GPT e Sonnet falhou
                    decision_correct = False
                    print("‚ùå Roteador errou: deveria ter usado GPT-5")

                # Atualiza shadow entry
                shadow_entry['actual_outcome'] = {
                    'success': success,
                    'attempts': ci_attempts,
                    'cost': cost,
                    'decision_correct': decision_correct
                }

    def analyze_shadow_period(self, min_tasks: int = 50) -> Dict:
        """
        An√°lise p√≥s shadow-mode (rodar ap√≥s 2-4 semanas)
        """
        if len(self.shadow_log) < min_tasks:
            return {
                'status': 'insufficient_data',
                'tasks': len(self.shadow_log),
                'required': min_tasks
            }

        # Filtra entries com outcome
        analyzed = [e for e in self.shadow_log if 'actual_outcome' in e]

        # Calcula accuracy
        correct_decisions = sum(
            1 for e in analyzed
            if e['actual_outcome']['decision_correct']
        )

        accuracy = correct_decisions / len(analyzed)

        # Breakdown por raz√£o
        reasons_breakdown = {}
        for e in analyzed:
            reason = e['reason']
            if reason not in reasons_breakdown:
                reasons_breakdown[reason] = {'total': 0, 'correct': 0}

            reasons_breakdown[reason]['total'] += 1
            if e['actual_outcome']['decision_correct']:
                reasons_breakdown[reason]['correct'] += 1

        # Economia vs desperd√≠cio
        savings = sum(
            0.60 for e in analyzed
            if not e['theoretical_decision'] and e['actual_outcome']['success']
        )

        waste = sum(
            0.60 for e in analyzed
            if e['theoretical_decision'] and e['actual_outcome']['success'] and e['actual_outcome']['attempts'] == 1
        )

        report = {
            'status': 'analysis_complete',
            'tasks_analyzed': len(analyzed),
            'accuracy': accuracy,
            'correct_decisions': correct_decisions,
            'incorrect_decisions': len(analyzed) - correct_decisions,
            'reasons_breakdown': reasons_breakdown,
            'financial': {
                'savings': savings,  # Economia por N√ÉO usar GPT quando desnecess√°rio
                'waste': waste,      # Desperd√≠cio por USAR GPT desnecessariamente
                'net': savings - waste
            },
            'recommendation': self.get_recommendation(accuracy, savings, waste)
        }

        print(f"""
üìä Shadow-Mode Analysis ({len(analyzed)} tasks):

Accuracy: {accuracy:.0%}
  Correct: {correct_decisions}
  Incorrect: {len(analyzed) - correct_decisions}

Financial Impact:
  Savings (avoided GPT): ${savings:.2f}
  Waste (unnecessary GPT): ${waste:.2f}
  Net: ${savings - waste:.2f}

Breakdown by Reason:
{self.format_reasons(reasons_breakdown)}

{report['recommendation']}
        """)

        return report

    def get_recommendation(self, accuracy: float, savings: float, waste: float) -> str:
        """
        Recomenda√ß√£o baseada em an√°lise
        """
        if accuracy > 0.80 and (savings - waste) > 0:
            return "‚úÖ ENABLE PRODUCTION MODE - Roteador est√° calibrado"
        elif accuracy > 0.70:
            return "‚ö†Ô∏è TUNE THRESHOLDS - Accuracy aceit√°vel, mas pode melhorar"
        else:
            return "‚ùå EXTEND SHADOW-MODE - Accuracy < 70%, precisa mais dados ou ajustes"

    def activate_production(self):
        """
        Ativa modo produ√ß√£o (s√≥ ap√≥s shadow-mode passar)
        """
        analysis = self.analyze_shadow_period()

        if 'ENABLE PRODUCTION' not in analysis['recommendation']:
            raise ValueError(f"Cannot activate production: {analysis['recommendation']}")

        self.shadow_mode = False
        self.production_start_date = datetime.now()

        print(f"""
üöÄ PRODUCTION MODE ACTIVATED
Shadow-mode accuracy: {analysis['accuracy']:.0%}
Expected monthly savings: ${analysis['financial']['net'] * 30:.2f}
        """)
```

**Timeline obrigat√≥rio:**

```python
# Semana 1-2: Shadow-Mode
orchestrator = ShadowModeDecisionEngine(shadow_mode=True)

for task in tasks:
    # Sempre usa Sonnet, mas registra decis√£o
    result = orchestrator.process_task(task)

# Semana 3: An√°lise
analysis = orchestrator.analyze_shadow_period(min_tasks=50)

if analysis['accuracy'] > 0.80:
    # Semana 4+: Produ√ß√£o
    orchestrator.activate_production()
else:
    # Ajustar thresholds e continuar shadow
    orchestrator.tune_thresholds(analysis)
```

---

## üìã Plano de Implementa√ß√£o REVISADO

### Fase 0: Prepara√ß√£o (4h) - NOVO!

```bash
# Setup observability infrastructure
- Criar logs/events.jsonl structure
- Dashboard generator scripts
- Circuit breaker config
- Slack webhooks
```

### Fase 1: MVP com Corre√ß√µes Cr√≠ticas (28h vs 20h original)

#### Dia 1-2: MCP Server + Observability (12h vs 8h)
```bash
# MCP Tools (8h)
- rag_retrieve com RRF+CE (4h)
- constitution_get com embeddings (2h)
- ci_validate com Docker sandbox (2h)

# Observability (4h) - NOVO!
- Eventos estruturados
- Dashboard generator
- Circuit breakers
```

#### Dia 3-4: Decision Engine + Shadow-Mode (12h vs 8h)
```python
# Decision Engine (8h)
- Regras fixas v1.0 (4h)
- Shadow-mode logic (2h)
- Cost tracking parametrizado (2h)

# Prompts (4h)
- Orchestrator para Sonnet
- Quando usar tools
- Cost awareness
```

#### Dia 5: Integration + Golden Tests (4h)
```bash
# Config (2h)
- .claude/settings.json
- Docker sandbox build
- Safe-ai-cli wrapper

# Golden Tests (2h) - NOVO!
- MCP fallback tests
- Sandbox validation
- End-to-end smoke test
```

**Deliverable Fase 1:** Sistema MVP com observability + seguran√ßa + shadow-mode

### Fase 2: Valida√ß√£o Shadow-Mode (2-4 semanas)

```python
# N√£o √© "implementa√ß√£o", √© OPERA√á√ÉO
- Rodar 10-20 tasks/dia
- Coletar decis√µes
- Analisar semanalmente
- Ajustar thresholds

# Gatilho para Fase 3:
if shadow_analysis.accuracy > 0.80:
    proceed_to_automation()
```

### Fase 3: Automa√ß√£o + Produ√ß√£o (16h)

#### Dia 6-7: API Mode + Produ√ß√£o (8h)
```python
# orchestrator_api.py (6h)
- Anthropic/OpenAI clients
- GitHub integration
- CI/CD adapter

# Production activation (2h)
- Desativar shadow-mode
- Enable roteador real
- Monitoring 24/7
```

#### Dia 8-9: Stack Adapters (4h)
```python
# ai_cli.py expansions
- Java Maven (1h)
- Java Gradle (1h)
- Go (1h)
- Testing (1h)
```

#### Dia 10: FinOps + Docs (4h)
```python
# FinOps dashboard (2h)
- Cost allocation
- Budget alerts
- ROI tracking

# Docs (2h)
- Setup guide
- Troubleshooting
- Runbooks
```

### Total Setup: 32h √ó $100/h = $3,200 (vs $2,000 v5.1)

**Diferen√ßa:** +12h para observability, seguran√ßa e shadow-mode (ESSENCIAIS!)

---

## ‚úÖ Go/No-Go Checklist PRODUCTION-READY

### CRITICAL (Must-Have para produ√ß√£o)

- [ ] **Observability estruturada**
  - [ ] Eventos JSON linha por linha
  - [ ] Dashboard di√°rio autom√°tico
  - [ ] Circuit breakers ativos
  - [ ] FinOps com custo real (n√£o estimado)

- [ ] **Seguran√ßa ci_validate**
  - [ ] Docker sandbox funcionando
  - [ ] Quotas (CPU/RAM/timeout) enforced
  - [ ] Command allowlist validada
  - [ ] Network isolation testado

- [ ] **Custos parametrizados**
  - [ ] DynamicPricing implementado
  - [ ] Custo real via API usage
  - [ ] Budget alerts configurados
  - [ ] ROI tracking ativo

- [ ] **Fallbacks MCP**
  - [ ] Golden tests passando
  - [ ] Fallback direto funcional
  - [ ] Paridade de resultados validada

- [ ] **Shadow-Mode completado**
  - [ ] 50+ tasks em shadow
  - [ ] Accuracy > 80%
  - [ ] Thresholds calibrados
  - [ ] Production mode ativado

### IMPORTANT (Should-Have para qualidade)

- [ ] **Reranker RRF+CE**
  - [ ] BM25+Vector fusion
  - [ ] Cross-encoder top-N
  - [ ] Recall@5 > 80%

- [ ] **Constitution embeddings**
  - [ ] Rule_id indexado
  - [ ] Sem√¢ntica funcionando
  - [ ] Tra√ßabilidade OK

- [ ] **Secrets masking**
  - [ ] .env, tokens mascarados
  - [ ] Logs sem PII
  - [ ] Compliance validado

### NICE-TO-HAVE (Roadmap p√≥s-valida√ß√£o)

- [ ] Features explic√°veis (Decision Engine)
- [ ] Hard negatives RAG
- [ ] Guardrails por repo/autor

---

## üöÄ MVP "Shippar Amanh√£" (Conting√™ncia)

Se precisar URG√äNCIA, cortar para m√≠nimo vi√°vel:

### Manter (Essencial)

1. **Observability m√≠nima**
   ```python
   # JSON events + dashboard di√°rio (8h)
   - log_event() estruturado
   - Daily report
   - Cost tracking real
   ```

2. **Sandbox b√°sico**
   ```bash
   # Docker + timeout (4h)
   docker run --rm --network=none --memory=512m --cpus=1 \
     timeout 300 python ai_cli.py run --task test
   ```

3. **Custo parametrizado**
   ```python
   # DynamicPricing (2h)
   cost = (tokens / 1000) * PRICING[model]
   ```

4. **Shadow-mode 1 semana**
   ```python
   # M√≠nimo 20 tasks (1 semana)
   if accuracy > 0.75: activate_production()
   ```

5. **Reranker b√°sico**
   ```python
   # RRF sem CE (2h)
   scores = rrf_fusion(bm25, vector)
   ```

**Total Urg√™ncia: 16h ($1,600)**

### Adicionar DEPOIS (quando estabilizar)

- Cross-Encoder reranking
- Constitution embeddings
- Guardrails granulares
- Features explic√°veis

---

## üìä Compara√ß√£o Final: v5.1 vs v5.2

| Aspecto | v5.1 "Production-Ready" | v5.2 REAL Production-Ready |
|---------|------------------------|---------------------------|
| **Observability** | ‚ùå Vago | ‚úÖ Estruturado (JSON+dashboard) |
| **Custos** | ‚ùå Hardcoded | ‚úÖ Parametrizado + real |
| **Seguran√ßa** | ‚ùå Execu√ß√£o direta | ‚úÖ Docker sandbox + quotas |
| **Reranker** | ‚ùå "Simple" | ‚úÖ RRF + Cross-Encoder |
| **Decision** | ‚ùå Produ√ß√£o imediata | ‚úÖ Shadow-mode 2-4 sem |
| **Fallbacks** | ‚ùå Mencionado | ‚úÖ Golden tests |
| **Constitution** | ‚ö†Ô∏è TF-IDF linhas | ‚úÖ Embeddings + rule_id |
| **Setup** | ‚è±Ô∏è 20h ($2,000) | ‚è±Ô∏è 32h ($3,200) |
| **Opex** | ‚è±Ô∏è 8h/m√™s ($800) | ‚è±Ô∏è 12-16h/m√™s ($1,200-1,600) |
| **Custo/m√™s** | üí∞ $1,556 | üí∞ $2,219 |
| **ROI** | üìà 248% (otimista) | üìà 141% (conservador) |
| **Production-Ready** | ‚ùå N√£o realmente | ‚úÖ Sim, com valida√ß√µes |

---

## üéØ Veredito v5.2

### O Que v5.1 Faltava (gaps cr√≠ticos)

1. ‚ùå **Observability** - operava √†s cegas
2. ‚ùå **Seguran√ßa** - ci_validate vulner√°vel
3. ‚ùå **Valida√ß√£o** - shadow-mode ausente
4. ‚ùå **Custos honestos** - hardcoded quebraria

### O Que v5.2 Entrega

1. ‚úÖ **Observability completa** - eventos + dashboard + circuit breakers
2. ‚úÖ **Seguran√ßa production-grade** - sandbox Docker + allowlist
3. ‚úÖ **Valida√ß√£o robusta** - shadow-mode obrigat√≥rio 2-4 semanas
4. ‚úÖ **Custos reais** - parametrizados, rastre√°veis, alertas
5. ‚úÖ **Qualidade RAG** - RRF+CE (+30% recall)
6. ‚úÖ **Rastreabilidade** - constitui√ß√£o com rule_id
7. ‚úÖ **Resili√™ncia** - fallbacks testados com golden tests

### Quando Aprovar para Produ√ß√£o

Checklist final:
- [ ] Fase 1 MVP implementada (32h)
- [ ] Shadow-mode rodou 2-4 semanas
- [ ] Accuracy > 80%
- [ ] Golden tests passando
- [ ] Dashboard + alertas funcionando
- [ ] Sandbox validado em staging
- [ ] Runbooks documentados
- [ ] Equipe treinada

**Ent√£o e somente ent√£o:** ‚úÖ Production-Ready REAL

---

**Aprovado para implementa√ß√£o Blueprint v5.2?**
